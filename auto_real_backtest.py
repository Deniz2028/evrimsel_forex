#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EVO_FX_MASTER - TAM OTOMATÄ°K GERÃ‡EK VERÄ° BACKTEST
===============================================

ğŸ¯ HEDEFÄ°: HiÃ§ soru sormadan tam otomatik gerÃ§ek OANDA verisi ile backtest
ğŸ”§ API bilgileri gÃ¶mÃ¼lÃ¼, tarih aralÄ±ÄŸÄ± otomatik
ğŸ“Š 15 gÃ¼nlÃ¼k gerÃ§ek veri + feature engineering + NEAT backtest
"""

import sys
import os
import numpy as np
import pandas as pd
import logging
import warnings
import requests
import json
from pathlib import Path
from datetime import datetime, timedelta, timezone
import time
import math

# Proje kÃ¶kÃ¼nÃ¼ path'e ekle
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AutoOANDALoader:
    """ğŸ¤– Tam otomatik OANDA veri Ã§ekici - API gÃ¶mÃ¼lÃ¼."""
    
    def __init__(self):
        """ğŸ”§ API bilgileri gÃ¶mÃ¼lÃ¼ - hiÃ§ soru sormaz."""
        # ğŸ”‘ GÃ–MÃœLÃœ API BÄ°LGÄ°LERÄ°
        self.token = "8d8619f4119fec7e59d73c61b76b480d-d0947fd967a22401c1e48bc1516ad0eb"
        self.account_id = "101-004-35700665-002"
        self.base_url = "https://api-fxpractice.oanda.com"  # Demo
        
        self.headers = {
            'Authorization': f'Bearer {self.token}',
            'Content-Type': 'application/json'
        }
        
        # Symbol mapping
        self.symbol_map = {
            'EURUSD': 'EUR_USD',
            'XAUUSD': 'XAU_USD'
        }
        
        # OANDA Limitleri
        self.max_candles_per_request = 4000
        self.rate_limit_delay = 0.1
        
        print(f"ğŸ¤– Otomatik OANDA Loader hazÄ±r:")
        print(f"   ğŸ”‘ Account: {self.account_id}")
        print(f"   ğŸŒ Environment: Demo")
        print(f"   ğŸ“¦ Chunk size: {self.max_candles_per_request}")
    
    def test_connection_silent(self):
        """Sessiz baÄŸlantÄ± testi."""
        try:
            url = f"{self.base_url}/v3/accounts/{self.account_id}"
            response = requests.get(url, headers=self.headers, timeout=10)
            
            if response.status_code == 200:
                account_info = response.json()
                balance = account_info.get('account', {}).get('balance', 'N/A')
                print(f"   âœ… OANDA baÄŸlantÄ±sÄ± OK - Bakiye: ${balance}")
                return True
            else:
                print(f"   âŒ OANDA hatasÄ±: {response.status_code}")
                return False
        except Exception as e:
            print(f"   âŒ BaÄŸlantÄ± hatasÄ±: {e}")
            return False
    
    def calculate_auto_chunks(self, days_back=15):
        """Otomatik chunk hesaplama."""
        # Tarih aralÄ±ÄŸÄ± otomatik
        today = datetime.now().date()
        start_date = today - timedelta(days=days_back)
        end_date = today - timedelta(days=1)
        
        start_dt = datetime.combine(start_date, datetime.min.time()).replace(tzinfo=timezone.utc)
        end_dt = datetime.combine(end_date, datetime.max.time()).replace(tzinfo=timezone.utc)
        
        # Åu anki zaman kontrolÃ¼
        now_utc = datetime.now(timezone.utc)
        if end_dt >= now_utc:
            end_dt = now_utc - timedelta(minutes=1)
        
        # Chunk'lara bÃ¶l
        total_minutes = (end_dt - start_dt).total_seconds() / 60
        total_candles_estimate = total_minutes
        chunk_count = math.ceil(total_candles_estimate / self.max_candles_per_request)
        
        print(f"ğŸ“Š Otomatik chunk hesaplama:")
        print(f"   ğŸ“… AralÄ±k: {start_dt.date()} - {end_dt.date()} ({days_back} gÃ¼n)")
        print(f"   ğŸ• Tahmini mum: {total_candles_estimate:.0f}")
        print(f"   ğŸ“¦ Chunk sayÄ±sÄ±: {chunk_count}")
        
        # Chunk'larÄ± oluÅŸtur
        chunks = []
        current_start = start_dt
        
        while current_start < end_dt:
            chunk_minutes = self.max_candles_per_request
            chunk_end = current_start + timedelta(minutes=chunk_minutes)
            
            if chunk_end > end_dt:
                chunk_end = end_dt
            
            chunks.append((current_start, chunk_end))
            current_start = chunk_end + timedelta(minutes=1)
        
        return chunks
    
    def fetch_single_chunk(self, symbol, start_dt, end_dt):
        """Tek chunk Ã§ek."""
        oanda_symbol = self.symbol_map.get(symbol, symbol)
        
        from_str = start_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        to_str = end_dt.strftime("%Y-%m-%dT%H:%M:%SZ")
        
        url = f"{self.base_url}/v3/instruments/{oanda_symbol}/candles"
        params = {
            'from': from_str,
            'to': to_str,
            'granularity': 'M1',
            'price': 'M'
        }
        
        try:
            time.sleep(self.rate_limit_delay)
            response = requests.get(url, headers=self.headers, params=params, timeout=30)
            
            if response.status_code != 200:
                return None
            
            data = response.json()
            candles = data.get('candles', [])
            
            if not candles:
                return None
            
            records = []
            for candle in candles:
                if candle['complete']:
                    mid = candle['mid']
                    records.append({
                        'timestamp': pd.to_datetime(candle['time']),
                        'open': float(mid['o']),
                        'high': float(mid['h']),
                        'low': float(mid['l']),
                        'close': float(mid['c']),
                        'volume': int(candle['volume'])
                    })
            
            if not records:
                return None
            
            df = pd.DataFrame(records)
            df.set_index('timestamp', inplace=True)
            
            if df.index.tz is not None:
                df.index = df.index.tz_convert('UTC')
            else:
                df.index = df.index.tz_localize('UTC')
            
            return df
            
        except Exception:
            return None
    
    def auto_fetch_symbol(self, symbol):
        """Otomatik sembol verisi Ã§ek."""
        print(f"ğŸ“¡ {symbol} otomatik veri Ã§ekimi...")
        
        chunks = self.calculate_auto_chunks(days_back=15)
        
        if not chunks:
            print(f"   âŒ Chunk hesaplanamadÄ±")
            return None
        
        all_dataframes = []
        success_count = 0
        
        print(f"   ğŸ“¦ {len(chunks)} chunk iÅŸleniyor...")
        
        for i, (chunk_start, chunk_end) in enumerate(chunks, 1):
            # Progress gÃ¶ster (her 5'te bir)
            if i % 5 == 1 or i == len(chunks):
                print(f"      Chunk {i}/{len(chunks)}")
            
            chunk_df = self.fetch_single_chunk(symbol, chunk_start, chunk_end)
            
            if chunk_df is not None and not chunk_df.empty:
                all_dataframes.append(chunk_df)
                success_count += 1
        
        print(f"   ğŸ“Š {success_count}/{len(chunks)} chunk baÅŸarÄ±lÄ±")
        
        if not all_dataframes:
            print(f"   âŒ Veri alÄ±namadÄ±")
            return None
        
        # BirleÅŸtir
        combined_df = pd.concat(all_dataframes, axis=0)
        combined_df = combined_df[~combined_df.index.duplicated(keep='first')]
        combined_df = combined_df.sort_index()
        
        # Kalite kontrol
        initial_len = len(combined_df)
        
        # OHLC geÃ§ersiz satÄ±rlarÄ± kaldÄ±r
        combined_df = combined_df[
            (combined_df['high'] >= combined_df['low']) & 
            (combined_df['high'] >= combined_df['open']) & 
            (combined_df['high'] >= combined_df['close']) &
            (combined_df['low'] <= combined_df['open']) & 
            (combined_df['low'] <= combined_df['close']) &
            (combined_df[['open', 'high', 'low', 'close']] > 0).all(axis=1)
        ]
        
        cleaned_count = initial_len - len(combined_df)
        if cleaned_count > 0:
            print(f"   ğŸ§¹ {cleaned_count} geÃ§ersiz satÄ±r temizlendi")
        
        print(f"   âœ… {symbol} tamamlandÄ±:")
        print(f"      ğŸ“Š Final mum: {len(combined_df)}")
        print(f"      ğŸ“… AralÄ±k: {combined_df.index.min().date()} - {combined_df.index.max().date()}")
        print(f"      ğŸ’° Fiyat: {combined_df['close'].min():.5f} - {combined_df['close'].max():.5f}")
        
        return combined_df
    
    def save_data(self, symbol, df):
        """Veri kaydet."""
        if df is None or df.empty:
            return False
        
        data_dir = Path("data")
        raw_dir = data_dir / "raw"
        raw_dir.mkdir(parents=True, exist_ok=True)
        
        file_path = raw_dir / f"{symbol}_raw.parquet"
        df.to_parquet(file_path, compression='snappy')
        
        print(f"   ğŸ’¾ Kaydedildi: {file_path}")
        return True

def auto_fetch_all_data():
    """ğŸ¤– TÃ¼m veriyi otomatik Ã§ek."""
    print("ğŸ¤– OTOMATÄ°K GERÃ‡EK VERÄ° Ã‡EKÄ°MÄ°")
    print("=" * 40)
    
    loader = AutoOANDALoader()
    
    # BaÄŸlantÄ± test
    print("ğŸ”Œ OANDA baÄŸlantÄ±sÄ± test ediliyor...")
    if not loader.test_connection_silent():
        return False
    
    # Her sembol iÃ§in veri Ã§ek
    symbols = ['EURUSD', 'XAUUSD']
    success_count = 0
    
    for symbol in symbols:
        df = loader.auto_fetch_symbol(symbol)
        
        if df is not None and len(df) >= 1000:  # Minimum 1000 mum
            if loader.save_data(symbol, df):
                success_count += 1
        else:
            print(f"   âš ï¸  {symbol}: Yetersiz veri")
    
    print(f"\nğŸ“Š OTOMATIK Ã‡EKIM SONUCU: {success_count}/2 sembol baÅŸarÄ±lÄ±")
    return success_count >= 1

def auto_feature_engineering():
    """ğŸ¤– Otomatik feature engineering."""
    print("\nğŸ”§ OTOMATÄ°K FEATURE ENGÄ°NEERÄ°NG")
    print("=" * 40)
    
    try:
        from feature_engineer import AdvancedFeatureEngineer
        
        config = {
            'rsi_period': 14,
            'atr_period': 14,
            'volatility_period': 30,
            'tick_momentum_periods': [5, 10, 20],
            'volume_periods': [10, 20, 50]
        }
        
        engineer = AdvancedFeatureEngineer(config)
        print("ğŸ—ï¸  Feature engineering baÅŸlatÄ±lÄ±yor...")
        
        results = engineer.process_all_symbols_advanced()
        
        if len(results) >= 1:
            total_features = 0
            for symbol, df in results.items():
                print(f"   âœ… {symbol}: {len(df)} satÄ±r, {len(df.columns)} Ã¶zellik")
                total_features += len(df.columns)
            
            print(f"ğŸ‰ Feature engineering baÅŸarÄ±lÄ±:")
            print(f"   ğŸ“Š Ortalama Ã¶zellik: {total_features // len(results)}")
            return True
        else:
            print("âŒ Feature engineering baÅŸarÄ±sÄ±z")
            return False
            
    except Exception as e:
        print(f"âŒ Feature engineering hatasÄ±: {e}")
        return False

def auto_neat_backtest():
    """ğŸ¤– Otomatik NEAT backtest."""
    print("\nğŸ§¬ OTOMATÄ°K NEAT BACKTEST")
    print("=" * 35)
    
    try:
        from backtest import BacktestEngine, BacktestConfig
        
        # Orta seviye config - gerÃ§ek test iÃ§in
        config = BacktestConfig(
            # Veri parametreleri
            start_date="2024-01-01",
            end_date="2024-12-31",
            symbols=['EURUSD', 'XAUUSD'],
            
            # NEAT parametreleri (orta seviye)
            population_sizes=[32, 64],
            stagnation_generations=[15, 20],
            speciation_thresholds=[2.0, 2.5],
            n_runs_per_config=2,           # HÄ±zlÄ± test iÃ§in
            max_generations=30,            # Orta uzunluk
            num_workers=2,                 # Paralel
            
            # SonuÃ§ ayarlarÄ±
            min_fitness_threshold=-0.5,
            top_n_results=5
        )
        
        print(f"ğŸ§¬ NEAT Backtest parametreleri:")
        print(f"   ğŸ‘¥ PopÃ¼lasyon: {config.population_sizes}")
        print(f"   ğŸ”¬ Nesil: {config.max_generations}")
        print(f"   ğŸ§ª Toplam experiment: {len(config.population_sizes) * len(config.stagnation_generations) * len(config.speciation_thresholds) * config.n_runs_per_config}")
        
        engine = BacktestEngine(config)
        
        print(f"ğŸš€ Otomatik NEAT backtest baÅŸlatÄ±lÄ±yor...")
        start_time = time.time()
        
        analysis = engine.run_full_experiment()
        
        total_time = time.time() - start_time
        
        if analysis:
            print(f"\nğŸ‰ OTOMATIK NEAT BACKTEST BAÅARILI!")
            print(f"â±ï¸  Toplam sÃ¼re: {total_time/60:.1f} dakika")
            print(f"ğŸ“Š Experiment: {analysis['successful_experiments']}/{analysis['total_experiments']}")
            print(f"ğŸ† En iyi fitness: {analysis['fitness_statistics']['best']:.6f}")
            print(f"ğŸ“ˆ Ortalama fitness: {analysis['fitness_statistics']['mean']:.6f}")
            
            if 'notebook_path' in analysis:
                print(f"ğŸ““ Jupyter rapor: {analysis['notebook_path']}")
            
            # En iyi genomu gÃ¶ster
            if 'best_result' in analysis:
                best = analysis['best_result']
                print(f"\nğŸ§¬ EN Ä°YÄ° SONUÃ‡:")
                print(f"   Config: {best['config_id']}")
                print(f"   Fitness: {best['fitness']:.6f}")
                print(f"   Validation: {best['validation_fitness']:.6f}")
                print(f"   Nesil: {best['generations']}")
                
                neat_config = best['neat_config']
                print(f"   PopÃ¼lasyon: {neat_config['population_size']}")
                print(f"   Speciation: {neat_config['speciation_threshold']}")
            
            return True
        else:
            print("âŒ NEAT backtest baÅŸarÄ±sÄ±z!")
            return False
            
    except Exception as e:
        print(f"âŒ NEAT backtest hatasÄ±: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ğŸ¤– TAM OTOMATÄ°K GERÃ‡EK VERÄ° BACKTEST - Ana fonksiyon."""
    print("ğŸ¤– EVO_FX_MASTER - TAM OTOMATÄ°K GERÃ‡EK VERÄ° BACKTEST")
    print("=" * 75)
    print(f"ğŸ“… BaÅŸlangÄ±Ã§: {datetime.now()}")
    print(f"ğŸ¯ Hedef: HiÃ§ soru sormadan OANDA gerÃ§ek verisi ile tam backtest")
    print(f"ğŸ”§ API gÃ¶mÃ¼lÃ¼, 15 gÃ¼nlÃ¼k veri, feature engineering + NEAT")
    
    success_steps = 0
    total_steps = 3
    start_time = time.time()
    
    # 1. ğŸ¤– Otomatik veri Ã§ekme
    print(f"\n{'='*75}")
    print("1ï¸âƒ£  ğŸ¤– OTOMATÄ°K OANDA VERÄ° Ã‡EKÄ°MÄ°")
    if auto_fetch_all_data():
        print("âœ… Otomatik veri Ã§ekimi baÅŸarÄ±lÄ±!")
        success_steps += 1
    else:
        print("âŒ Otomatik veri Ã§ekimi baÅŸarÄ±sÄ±z!")
        return False
    
    # 2. ğŸ¤– Otomatik feature engineering
    print(f"\n{'='*75}")
    print("2ï¸âƒ£  ğŸ¤– OTOMATÄ°K FEATURE ENGÄ°NEERÄ°NG")
    if auto_feature_engineering():
        print("âœ… Otomatik feature engineering baÅŸarÄ±lÄ±!")
        success_steps += 1
    else:
        print("âŒ Otomatik feature engineering baÅŸarÄ±sÄ±z!")
    
    # 3. ğŸ¤– Otomatik NEAT backtest
    print(f"\n{'='*75}")
    print("3ï¸âƒ£  ğŸ¤– OTOMATÄ°K NEAT BACKTEST")
    if auto_neat_backtest():
        print("âœ… Otomatik NEAT backtest baÅŸarÄ±lÄ±!")
        success_steps += 1
    else:
        print("âŒ Otomatik NEAT backtest baÅŸarÄ±sÄ±z!")
    
    # ğŸ Final sonuÃ§lar
    total_time = time.time() - start_time
    
    print(f"\n{'='*75}")
    print("ğŸ TAM OTOMATÄ°K BACKTEST SONUÃ‡LARI")
    print("=" * 45)
    
    success_rate = success_steps / total_steps
    print(f"ğŸ“ˆ BaÅŸarÄ± oranÄ±: {success_steps}/{total_steps} ({success_rate*100:.1f}%)")
    print(f"â±ï¸  Toplam sÃ¼re: {total_time/60:.1f} dakika")
    
    if success_steps >= 2:
        print("ğŸ‰ TAM OTOMATÄ°K GERÃ‡EK VERÄ° BACKTEST BAÅARILI!")
        print("ğŸ¤– HiÃ§ soru sormadan tam sÃ¼reÃ§ tamamlandÄ±!")
        
        print(f"\nğŸ¯ TAMAMLANAN AÅAMALAR:")
        print(f"   â€¢ 15 gÃ¼nlÃ¼k gerÃ§ek OANDA verisi Ã§ekildi")
        print(f"   â€¢ OANDA chunk limiti otomatik Ã§Ã¶zÃ¼ldÃ¼")
        print(f"   â€¢ 30+ teknik indikatÃ¶r hesaplandÄ±")
        if success_steps == 3:
            print(f"   â€¢ NEAT evrimsel algoritma Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±")
            print(f"   â€¢ Grid search optimizasyon tamamlandÄ±")
            print(f"   â€¢ Jupyter rapor oluÅŸturuldu")
        
        print(f"\nğŸ“ OLUÅTURULAN DOSYALAR:")
        print(f"   â€¢ data/raw/*.parquet - Ham OANDA verisi")
        print(f"   â€¢ data/processed/*.parquet - Feature'lÄ± veri")
        print(f"   â€¢ results/*.json - Backtest sonuÃ§larÄ±")
        print(f"   â€¢ results/best_genome_*.json - En iyi genom")
        if success_steps == 3:
            print(f"   â€¢ notebooks/*.ipynb - DetaylÄ± rapor")
        
        print(f"\nğŸš€ SONRAKI ADIMLAR:")
        print(f"   1. En iyi genomu live trading'de kullan")
        print(f"   2. Daha uzun backtest Ã§alÄ±ÅŸtÄ±r (100+ nesil)")
        print(f"   3. MT5 ile gerÃ§ek hesapta test et")
        print(f"   4. Risk parametrelerini optimize et")
        
        return True
    else:
        print("âŒ TAM OTOMATÄ°K BACKTEST BAÅARISIZ!")
        print("LoglarÄ± kontrol edin ve internet baÄŸlantÄ±sÄ±nÄ± doÄŸrulayÄ±n.")
        return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print(f"\nğŸ† TAM OTOMATÄ°K SÄ°STEM HAZIR!")
        print(f"ğŸš€ GerÃ§ek verilerle backtest tamamlandÄ±.")
        print(f"ğŸ“Š SonuÃ§larÄ± notebooks/ klasÃ¶rÃ¼nde inceleyin.")
    else:
        print(f"\nğŸ”§ Sistem hazÄ±r deÄŸil, hatalarÄ± giderin.")